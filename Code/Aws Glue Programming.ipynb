{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 2\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 2\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 2880\nSession ID: b682d36d-c666-4356-957e-9a9fbaca7e74\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session b682d36d-c666-4356-957e-9a9fbaca7e74 to get into ready status...\nSession b682d36d-c666-4356-957e-9a9fbaca7e74 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "dyf = glueContext.create_dynamic_frame.from_catalog(database='bt-course-db-final', table_name='raw_data_2024_mm_06')\ndyf.printSchema()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- date: string\n|-- time: string\n|-- euipment id: string\n|-- equipment name: string\n|-- equipment type: string\n|-- attribute name: string\n|-- attribute value: long\n|-- desc: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data which shows the 20 rows by default.\n",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "df = dyf.toDF()\ndf.show()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"editable": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------+--------+-----------+--------------+---------------+--------------+---------------+--------------------+\n|     date|    time|euipment id|equipment name| equipment type|attribute name|attribute value|                desc|\n+---------+--------+-----------+--------------+---------------+--------------+---------------+--------------------+\n|1/06/2024|17:30:28|   EQU-ID-1|  server-web-1|     web-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|   EQU-ID-2|  server-web-2|     web-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|   EQU-ID-3|  server-wev-3|     web-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|   EQU-ID-4|  server-app-1|     app-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|   EQU-ID-5|  server-app-2|     app-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|   EQU-ID-6|  server-app-3|     app-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|   EQU-ID-7|  server-app-4|     app-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|   EQU-ID-8|  server-app-5|     app-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|   EQU-ID-9|  server-app-6|     app-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|  EQU-ID-10|   server-DB-1|database-server| CPUUtlization|             10|ideal should stay...|\n|1/06/2024|17:30:28|  EQU-ID-10|   server-DB-1|database-server|   storageused|             10|HardDisk Size is ...|\n|1/06/2024|17:30:28|  EQU-ID-10|   server-DB-1|database-server|    memoryused|             10|                    |\n|1/06/2024|17:30:28|  EQU-ID-11|   server-DB-2|database-server| CPUUtlization|             10|                    |\n|1/06/2024|17:30:28|  EQU-ID-11|   server-DB-2|database-server|   storageused|             10|HardDisk Size is ...|\n|1/06/2024|17:30:28|  EQU-ID-11|   server-DB-2|database-server|    memoryused|             10|                    |\n|1/06/2024|17:30:28|  EQU-ID-12|   server-DB-3|database-server| CPUUtlization|             10|                    |\n|1/06/2024|17:30:28|  EQU-ID-12|   server-DB-3|database-server|   storageused|             10|HardDisk Size is ...|\n|1/06/2024|17:30:28|  EQU-ID-12|   server-DB-3|database-server|    memoryused|             10|                    |\n|1/06/2024|17:30:28|  EQU-ID-13|   Fire-sensor|            SEN|  smokeDectted|              0|0 for No and  1 f...|\n|1/06/2024|17:30:28|  EQU-ID-14|   Temp-sensor|            SEN|          temp|             10|ideal should stay...|\n+---------+--------+-----------+--------------+---------------+--------------+---------------+--------------------+\nonly showing top 20 rows\n\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Display full columns contents",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df.show(truncate=False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------+--------+-----------+--------------+---------------+--------------+---------------+---------------------------+\n|date     |time    |euipment id|equipment name|equipment type |attribute name|attribute value|desc                       |\n+---------+--------+-----------+--------------+---------------+--------------+---------------+---------------------------+\n|1/06/2024|17:30:28|EQU-ID-1   |server-web-1  |web-server     |CPUUtlization |10             |ideal should stay below 80 |\n|1/06/2024|17:30:28|EQU-ID-2   |server-web-2  |web-server     |CPUUtlization |10             |ideal should stay below 81 |\n|1/06/2024|17:30:28|EQU-ID-3   |server-wev-3  |web-server     |CPUUtlization |10             |ideal should stay below 82 |\n|1/06/2024|17:30:28|EQU-ID-4   |server-app-1  |app-server     |CPUUtlization |10             |ideal should stay below 83 |\n|1/06/2024|17:30:28|EQU-ID-5   |server-app-2  |app-server     |CPUUtlization |10             |ideal should stay below 84 |\n|1/06/2024|17:30:28|EQU-ID-6   |server-app-3  |app-server     |CPUUtlization |10             |ideal should stay below 85 |\n|1/06/2024|17:30:28|EQU-ID-7   |server-app-4  |app-server     |CPUUtlization |10             |ideal should stay below 86 |\n|1/06/2024|17:30:28|EQU-ID-8   |server-app-5  |app-server     |CPUUtlization |10             |ideal should stay below 87 |\n|1/06/2024|17:30:28|EQU-ID-9   |server-app-6  |app-server     |CPUUtlization |10             |ideal should stay below 88 |\n|1/06/2024|17:30:28|EQU-ID-10  |server-DB-1   |database-server|CPUUtlization |10             |ideal should stay below 89 |\n|1/06/2024|17:30:28|EQU-ID-10  |server-DB-1   |database-server|storageused   |10             |HardDisk Size is 500GB     |\n|1/06/2024|17:30:28|EQU-ID-10  |server-DB-1   |database-server|memoryused    |10             |                           |\n|1/06/2024|17:30:28|EQU-ID-11  |server-DB-2   |database-server|CPUUtlization |10             |                           |\n|1/06/2024|17:30:28|EQU-ID-11  |server-DB-2   |database-server|storageused   |10             |HardDisk Size is 500GB     |\n|1/06/2024|17:30:28|EQU-ID-11  |server-DB-2   |database-server|memoryused    |10             |                           |\n|1/06/2024|17:30:28|EQU-ID-12  |server-DB-3   |database-server|CPUUtlization |10             |                           |\n|1/06/2024|17:30:28|EQU-ID-12  |server-DB-3   |database-server|storageused   |10             |HardDisk Size is 500GB     |\n|1/06/2024|17:30:28|EQU-ID-12  |server-DB-3   |database-server|memoryused    |10             |                           |\n|1/06/2024|17:30:28|EQU-ID-13  |Fire-sensor   |SEN            |smokeDectted  |0              |0 for No and  1 for yes    |\n|1/06/2024|17:30:28|EQU-ID-14  |Temp-sensor   |SEN            |temp          |10             |ideal should stay below 20 |\n+---------+--------+-----------+--------------+---------------+--------------+---------------+---------------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Display 2 rows and full columns contents",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df.show(2,truncate=False) ",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------+--------+-----------+--------------+--------------+--------------+---------------+---------------------------+\n|date     |time    |euipment id|equipment name|equipment type|attribute name|attribute value|desc                       |\n+---------+--------+-----------+--------------+--------------+--------------+---------------+---------------------------+\n|1/06/2024|17:30:28|EQU-ID-1   |server-web-1  |web-server    |CPUUtlization |10             |ideal should stay below 80 |\n|1/06/2024|17:30:28|EQU-ID-2   |server-web-2  |web-server    |CPUUtlization |10             |ideal should stay below 81 |\n+---------+--------+-----------+--------------+--------------+--------------+---------------+---------------------------+\nonly showing top 2 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n",
			"metadata": {
				"editable": true,
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "s3output = glueContext.getSink(\n  path=\"s3://bucket_name/folder_name\",\n  connection_type=\"s3\",\n  updateBehavior=\"UPDATE_IN_DATABASE\",\n  partitionKeys=[],\n  compression=\"snappy\",\n  enableUpdateCatalog=True,\n  transformation_ctx=\"s3output\",\n)\ns3output.setCatalogInfo(\n  catalogDatabase=\"demo\", catalogTableName=\"populations\"\n)\ns3output.setFormat(\"glueparquet\")\ns3output.writeFrame(DyF)",
			"metadata": {
				"editable": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "Test example",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "markdown",
			"source": "s3output = glueContext.getSink(\n  path=\"s3://bucket_name/folder_name\",\n  connection_type=\"s3\",\n  updateBehavior=\"UPDATE_IN_DATABASE\",\n  partitionKeys=[],\n  compression=\"snappy\",\n  enableUpdateCatalog=True,\n  transformation_ctx=\"s3output\",\n)\ns3output.setCatalogInfo(\n  catalogDatabase=\"demo\", catalogTableName=\"populations\"\n)\ns3output.setFormat(\"glueparquet\")\ns3output.writeFrame(DyF)",
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": "# Heading 1",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}